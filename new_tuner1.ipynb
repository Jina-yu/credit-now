{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = '../../' if os.getcwd().split('/')[-1] != 'credit-now' else './'\n",
    "os.chdir(root_dir)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "import keras_tuner as kt\n",
    "\n",
    "import credit_data\n",
    "import visualkeras\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18519, 18584) (7938, 18584) (18519, 3) (7938, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_label, test_label = credit_data.load_train_data()\n",
    "\n",
    "train_data = train_data.todense()\n",
    "test_data = test_data.todense()\n",
    "train_label = utils.to_categorical(train_label)\n",
    "test_label = utils.to_categorical(test_label)\n",
    "\n",
    "print(train_data.shape, test_data.shape, train_label.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b2M1Op-Hb7uI"
   },
   "outputs": [],
   "source": [
    "def build_hyper_model(hp):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    hp_units = hp.Int('units_input', min_value=32, max_value=512, step=32)\n",
    "    hp_activations = hp.Choice('activation_input', values=['relu', 'elu'])\n",
    "    model.add(layers.Dense(input_dim=18584, units=hp_units, activation=hp_activations, kernel_initializer=he_uniform()))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    for layer_num in range(hp.Int('num_layers', min_value=1, max_value=5)):\n",
    "        hp_units = hp.Int('units_' + str(layer_num), min_value=32, max_value=512, step=32)\n",
    "        hp_activations = hp.Choice('activation_' + str(layer_num), values=['relu', 'elu'])\n",
    "        model.add(layers.Dense(hp_units, activation=hp_activations, kernel_initializer=he_uniform()))\n",
    "        hp_dropouts = hp.Float('dropout_' + str(layer_num), 0.0, 0.5, step=0.1)\n",
    "        model.add(layers.Dropout(hp_dropouts))\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "    model.compile(optimizer=Adam(hp_learning_rate),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYthW2b6fiP",
    "outputId": "164fb118-ee7c-4925-b136-9b7e093b2b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.BayesianOptimization(build_hyper_model,\n",
    "                                objective = 'val_accuracy',\n",
    "                                max_trials = 100,\n",
    "                                directory = 'keras_tuner',\n",
    "                                project_name = 'new_bayes_depth5')\n",
    "\n",
    "# tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXSCIHWE6j_2",
    "outputId": "c20d6898-0221-4346-a420-84b7023e552f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 05m 16s]\n",
      "val_accuracy: 0.642227292060852\n",
      "\n",
      "Best val_accuracy So Far: 0.6587302088737488\n",
      "Total elapsed time: 01h 04m 00s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_data, train_label, batch_size=100, epochs=10, validation_data=(test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDlJzL14GVXR",
    "outputId": "bc282bbd-e3cb-4178-ab01-64a2d89e2f83"
   },
   "outputs": [],
   "source": [
    "tuner.results_summary(num_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFbk0Bvo36HR",
    "outputId": "9f835481-18d7-4967-92b5-c217e76daedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance rank : 0\n",
      "{'units_input': 512, 'activation_input': 'elu', 'num_layers': 1, 'units_0': 480, 'activation_0': 'elu', 'dropout_0': 0.5, 'learning_rate': 0.01, 'units_1': 512, 'activation_1': 'elu', 'dropout_1': 0.4, 'units_2': 512, 'activation_2': 'elu', 'dropout_2': 0.1, 'units_3': 32, 'activation_3': 'relu', 'dropout_3': 0.5, 'units_4': 320, 'activation_4': 'relu', 'dropout_4': 0.0}\n",
      "\n",
      "Model performance rank : 1\n",
      "{'units_input': 512, 'activation_input': 'elu', 'num_layers': 1, 'units_0': 512, 'activation_0': 'elu', 'dropout_0': 0.5, 'learning_rate': 0.01, 'units_1': 512, 'activation_1': 'elu', 'dropout_1': 0.5, 'units_2': 512, 'activation_2': 'elu', 'dropout_2': 0.2, 'units_3': 32, 'activation_3': 'relu', 'dropout_3': 0.5, 'units_4': 352, 'activation_4': 'relu', 'dropout_4': 0.0}\n",
      "\n",
      "Model performance rank : 2\n",
      "{'units_input': 512, 'activation_input': 'elu', 'num_layers': 5, 'units_0': 512, 'activation_0': 'elu', 'dropout_0': 0.5, 'learning_rate': 0.01, 'units_1': 512, 'activation_1': 'elu', 'dropout_1': 0.5, 'units_2': 512, 'activation_2': 'elu', 'dropout_2': 0.0, 'units_3': 32, 'activation_3': 'elu', 'dropout_3': 0.30000000000000004, 'units_4': 96, 'activation_4': 'relu', 'dropout_4': 0.0}\n",
      "\n",
      "\n",
      "The hyperparameter search is complete. \n",
      "* Optimal # of layers : 1\n",
      "* Optimal value of the learning-rate : 0.01\n",
      "Layer 0 - # of Perceptrons : 480\n",
      "Layer 0 - Applied activation function : elu\n"
     ]
    }
   ],
   "source": [
    "top3_models = tuner.get_best_hyperparameters(num_trials=3)\n",
    "# print(tuner.get_best_hyperparameters(num_trials=3)[0].space)\n",
    "# print(tuner.get_best_hyperparameters(num_trials=3)[0].values)\n",
    "\n",
    "for idx, model in enumerate(top3_models):\n",
    "    print('Model performance rank :', idx)\n",
    "    print(model.values)\n",
    "    print()\n",
    "\n",
    "best_hps = top3_models[0]\n",
    "\n",
    "print(\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "* Optimal # of layers : {}\n",
    "* Optimal value of the learning-rate : {}\"\"\".format(best_hps.get('num_layers'), best_hps.get('learning_rate')))\n",
    "\n",
    "for layer_num in range(best_hps.get('num_layers')):\n",
    "    print('Layer {} - # of Perceptrons :'.format(layer_num), best_hps.get('units_' + str(layer_num)))\n",
    "    print('Layer {} - Applied activation function :'.format(layer_num), best_hps.get('activation_' + str(layer_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oO2QFJn0L7z_",
    "outputId": "a90701e0-f12c-41b0-ac7f-35355e5f7f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               34816     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 480)               246240    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 480)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 480)              1920      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1443      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286,467\n",
      "Trainable params: 284,483\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "\n",
      "214/214 [==============================] - 5s 21ms/step - loss: 0.8151 - accuracy: 0.6921\n",
      "Cross-entropy : 0.8150773644447327\n",
      "Accuracy : 0.6921384930610657\n"
     ]
    }
   ],
   "source": [
    "top_models = tuner.get_best_models(num_models=3)\n",
    "top_model = top_models[0]\n",
    "top_model.summary()\n",
    "print()\n",
    "\n",
    "results = top_model.evaluate(test_data, test_label)\n",
    "print('Cross-entropy :', results[0])\n",
    "print('Accuracy :', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=344x63>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualkeras.layered_view(top_model, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.save('models/model_bayes5.h5')\n",
    "dump(best_hps, 'models/params_bayes5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j5xYX3dOHqV",
    "outputId": "ab3c7d96-0ae8-41e7-f6f7-0eb96014f5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "160/160 [==============================] - 6s 30ms/step - loss: 1.0274 - accuracy: 0.5939 - val_loss: 1.0029 - val_accuracy: 0.5581\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 4s 23ms/step - loss: 0.9212 - accuracy: 0.6323 - val_loss: 0.8697 - val_accuracy: 0.6662\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 4s 25ms/step - loss: 0.8768 - accuracy: 0.6590 - val_loss: 0.8448 - val_accuracy: 0.6740\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 4s 23ms/step - loss: 0.8499 - accuracy: 0.6745 - val_loss: 0.8202 - val_accuracy: 0.6867\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 4s 23ms/step - loss: 0.8327 - accuracy: 0.6818 - val_loss: 0.8312 - val_accuracy: 0.6776\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 3s 21ms/step - loss: 0.8271 - accuracy: 0.6814 - val_loss: 0.8237 - val_accuracy: 0.6836\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 0.8213 - accuracy: 0.6854 - val_loss: 0.8226 - val_accuracy: 0.6880\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 4s 22ms/step - loss: 0.8176 - accuracy: 0.6862 - val_loss: 0.8096 - val_accuracy: 0.6879\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 0.8132 - accuracy: 0.6875 - val_loss: 0.8383 - val_accuracy: 0.6826\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 4s 24ms/step - loss: 0.8138 - accuracy: 0.6861 - val_loss: 0.8064 - val_accuracy: 0.6869\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.8064 - accuracy: 0.6869\n",
      "Cross-entropy : 0.8064232468605042\n",
      "Accuracy : 0.6868583559989929\n"
     ]
    }
   ],
   "source": [
    "best_hps = load('models/params_bayes5.pkl')\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(train_data, train_label, batch_size=100, epochs=10, validation_data=(test_data, test_label))\n",
    "\n",
    "results = model.evaluate(test_data, test_label)\n",
    "print('Cross-entropy :', results[0])\n",
    "print('Accuracy :', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71a6a35a5e2082b4baf2330a569e10365064de6ba0b0fb1962d72bc015b0efc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
